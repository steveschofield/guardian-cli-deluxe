# Guardian Configuration File
# Default settings for AI-powered penetration testing

# AI Configuration
ai:
  # Supported providers: gemini, ollama, openrouter, huggingface
  # provider: openrouter
  # model: "xiaomi/mimo-v2-flash:free"
  # model: "qwen/qwen3-coder:free"
  # base_url: "https://openrouter.ai/api/v1"
  #
  # Ollama example:
  provider: ollama
  model: "llama3.1:8b"
  # model: deepseek-r1:8b 
  # model: llama3.2:3b
  # model: "DeepHat/DeepHat-V1-7B"
  base_url: "http://192.168.1.69:11434"
  #
  # Gemini (Vertex AI via ADC) example (recommended for higher limits):
  # - Install deps: pip install -U google-genai
  # - Authenticate: gcloud auth application-default login
  # - Configure project id OR project number below (NOT an API key):
  
  # provider: gemini
  # model: "gemini-3-flash-preview"
  # temperature: 0.2
  # vertexai: true
  # project: "project-id-"
  # location: "global"

  # Hugging Face Serverless Inference API example:
  # - Create a token (fine-grained is recommended) and set env HF_TOKEN
  # - Model is a Hub repo id, e.g. meta-llama/Meta-Llama-3-8B-Instruct
  # - Use base_url: https://router.huggingface.co/hf-inference/models
  #
  # Hugging Face Router (OpenAI-compatible) example:
  # - Use base_url: https://router.huggingface.co/v1
  # provider: huggingface
  # model: "deepseek-ai/DeepSeek-R1"
  # base_url: "https://router.huggingface.co/v1"
  # hf_max_retries: 4

  temperature: 0.2

  # Log full LLM request/response payloads to JSONL
  log_llm_io_file: true
  log_llm_full_io: true

  max_tokens: 8192
  # Request timeout for provider HTTP calls (seconds). Some providers may still impose their own limits.
  timeout: 600
  # Overall time budget for an LLM call at the agent level (seconds).
  # If unset, Guardian falls back to `ai.timeout`.
  llm_timeout_seconds: 600
  # Retries for LLM timeouts (set to 0 to disable).
  llm_retry_count: 2
  llm_retry_backoff_seconds: 2
  llm_retry_max_backoff_seconds: 30
  llm_retry_jitter_seconds: 0.5
  max_input_chars: 100000
  # Max characters of tool output to include in LLM prompts (larger = more context, more tokens/cost)
  max_tool_output_chars: 25000
  # Optional: desired context window size (only enforced for Ollama via num_ctx; other providers may ignore).
  context_window: 200000

# Penetration Testing Settings
pentest:
  # Safety mode prevents automatic execution of risky commands
  safe_mode: false
  
  # Maximum number of tools to run in parallel
  max_parallel_tools: 5
  
  # Require user confirmation before executing any tool
  require_confirmation: false
  
  # Maximum scan depth for recursive operations
  max_depth: 5
  
  # Request timeout for tools (seconds)
  tool_timeout: 900

# Output Settings
output:
  # Default format: markdown, html, json
  format: markdown
  
  # Save path for reports and outputs
  save_path: ./reports
  
  # Include AI reasoning in reports
  include_reasoning: true
  
  # Verbosity level: quiet, normal, verbose, debug
  verbosity: normal
  
  # Memory optimization settings
  compress_large_outputs: true
  max_output_size_mb: 50
  truncate_verbose_tools: true

# Scope Validation
scope:
  # Blacklisted IP ranges (CIDR notation)
  blacklist:
  #  - 127.0.0.0/8
  
  # Require explicit scope file for scanning
  require_scope_file: false
  
  # Maximum number of targets per scan
  max_targets: 100

# Tool Configuration
tools:
  nmap:
    enabled: true
    # Recon / baseline enumeration
    default_args: "-sV -sC"
    # Vulnerability script sweep (NSE "vuln" category)
    # Example: nmap -sV --script vuln <target>
    vuln_args: "-sV --script vuln"
    timing: T4

  amass:
    enabled: true
    args: "-passive"

  whois:
    enabled: true

  wappalyzer:
    enabled: true
    # args: "--pretty"

  ffuf:
    enabled: true
    wordlist: "/usr/share/wordlists/dirb/common.txt"
    vhost_wordlist: "/usr/share/seclists/Discovery/DNS/subdomains-top1million-20000.txt"
    threads: 40
    timeout: 10
    follow_redirects: false

  kiterunner:
    enabled: true
    # binary: "kr"
    wordlist: "./tools/vendor/kiterunner/routes-small.json"
    # args: "scan {target} -w /path/to/routes.json"

  hydra:
    enabled: true
    # Adjust module/paths for your target (default uses HTTPS GET to "/").
    args: "-L /usr/share/seclists/Usernames/top-usernames-shortlist.txt -P /usr/share/seclists/Passwords/Common-Credentials/10k-most-common.txt -s 443 {target} https-get /"

  jwt_tool:
    enabled: true
    # If you have a JWT, set token or add headers/cookies via args.
    args: "-t {target} -M pb"

  graphql_cop:
    enabled: true
    # script: "./tools/vendor/graphql-cop/graphql-cop.py"
    args: "-t {target}/graphql"

  tplmap:
    enabled: true
    args: "-u {target}"

  upload_scanner:
    enabled: true
    args: "--url {target}"

  csrf_tester:
    enabled: true
    args: "--url {target}"

  jsparser:
    enabled: true
    # script: "/path/to/JSParser.py"
    # args: "-u {target}"

  masscan:
    enabled: true
    ports: "22,53,80,135,139,443,445,3389"
    rate: 10000

  enum4linux:
    enabled: true
    args: "-a"
    # Null session defaults (avoid interactive password prompts; works only if anonymous is allowed)
    username: ""
    password: ""

  smbclient:
    enabled: true
    # username: "guest"
    # password: ""

  showmount:
    enabled: true

  onesixtyone:
    enabled: true
    # wordlist: "/usr/share/seclists/Discovery/SNMP/snmp-default-community-strings.txt"
    community: "public"

  snmpwalk:
    enabled: true
    version: "2c"
    community: "public"

  xprobe2:
    enabled: true
    args: "-v"
    
  httpx:
    enabled: true
    threads: 50
    timeout: 10
    
  subfinder:
    enabled: true
    sources: ["crtsh", "hackertarget"]

  dnsx:
    enabled: true
    # Query multiple DNS record types; in safe_mode we avoid AXFR attempts.
    recon: true
    threads: 50
    
  nuclei:
    enabled: true
    severity: ["critical", "high"]
    # Nuclei can take longer than the default workflow timeout depending on template set/target size.
    tool_timeout: 900
    templates_paths:
      - ~/nuclei-templates
    # Nuclei tags are template-defined (run `nuclei -tgl` to see what's available in your template set).
    # This set aims for broad OWASP-style coverage without running the entire template corpus.
    tags: ["cve", "rce", "sqli", "xss", "default", "default-login"]
    rate_limit: 50
  
  schemathesis:
    enabled: true
    # Required: OpenAPI schema URL or path
    schema: "{target}/openapi.json"
    # Optional: base URL for the API (defaults to target)
    # base_url: "https://api.example.com"
    # Optional tuning
    # workers: 4
    # checks: "all"
    # max_examples: 50

  naabu:
    enabled: true
    rate: 1000
    top_ports: 100
    exclude_cdn: true

  katana:
    enabled: true
    depth: 3
    concurrency: 25

  asnmap:
    enabled: true
    include_org: true

  waybackurls:
    enabled: true

  zap:
    enabled: true
    # Run mode: "docker" recommended, or "local" for a locally-installed ZAP script.
    mode: docker
    docker_image: "ghcr.io/zaproxy/zaproxy:stable"
    # baseline = passive (safer), full = active scan (requires pentest.safe_mode: false)
    scan: full
    # Time budget for the scan scripts (minutes)
    max_minutes: 45
    # Use AJAX spider for SPA apps (daemon mode when enabled)
    ajax_spider: true
    # Ignore robots.txt for deeper crawl
    ignore_robots: true
    # Seed URLs (comma-separated) or a file of URLs
    # seed_urls: ""
    # seed_urls_file: ""
    seed_urls_from_context: true
    # Create an authenticated context (optional; use for login-required apps)
    # context_name: "Guardian"
    # include_regex: "https://example.com.*"
    # login_url: "https://example.com/login"
    # login_request_data: "username={username}&password={password}"
    # username: "testuser"
    # password: "testpass"
    # username_field: "username"
    # password_field: "password"
    # logged_in_regex: "Logout"
    # logged_out_regex: "Login"
    # Export HAR when using daemon mode (useful for importing into Burp/other tools)
    export_har: false
    # Run additional ZAP scan when available
    run_additional_scan: true

  burp_pro:
    enabled: true
    # Run additional Burp Pro scan when available (macOS only)
    run_additional_scan: false
    scan_type: "crawl-and-audit"
    # Time budget for scan (minutes)
    max_minutes: 30

# Workflow Settings
workflows:
  # Default workflow timeout (seconds)
  timeout: 3600
  # Save session progress after each step (enables resume support)
  save_progress: true
  
  # Optional: run Planner checkpoints during scripted workflows (recon/web/network)
  # Autonomous runs Planner by default
  use_planner: false
  # Valid values: step names (e.g. "port_scanning"), step types ("analysis", "report"), or "all"
  planner_checkpoints: ["port_scanning", "web_discovery", "analysis", "report"]
  # Optional: per-step tool preferences for built-in workflows
  # tool_preferences:
  #   recon:
  #     port_scanning:
  #       preferred: ["naabu"]
  #       primary: "nmap"
  #   web:
  #     web_discovery:
  #       preferred: ["httpx", "gospider"]
  
  # Save intermediate results
  save_intermediate: true
  
  # Resume from checkpoint on failure
  resume_on_failure: true

# Logging
logging:
  # Enable audit logging
  enabled: true
  
  # Log file path
  path: ./logs/guardian.log
  
  # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: INFO
  
  # Log AI decisions
  log_ai_decisions: true
  
  # Log LLM requests and responses
  log_llm_requests: true
  log_llm_responses: true
  
  # Debug mode
  debug: true
  
  # Log tool executions and outputs
  log_tool_executions: true
  
  # Log workflow progress
  log_workflow_progress: true
  
  # Log memory/context updates
  log_memory_updates: true
  
  # Rotate log files when they get large
  rotate_logs: true
  max_log_size_mb: 100

# Error Handling
error_handling:
  # Enable comprehensive error handling
  enabled: true
  
  # Continue on recoverable errors
  continue_on_recoverable: true
  
  # Retry attempts for transient failures
  max_retries: 3
  
  # Backoff delay for retries (seconds)
  retry_delay: 30
  
  # Log all errors to file
  log_errors: true
